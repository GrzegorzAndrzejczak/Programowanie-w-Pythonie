{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrzegorzAndrzejczak/Programowanie-w-Pythonie/blob/main/notebooks/F%26B-pr%C3%B3bkowanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfFy280eL_cH"
      },
      "source": [
        "# Frequentism and Bayesianism -- David Barber (2020), Robert Casella oraz Jake VanderPlas (jakevdp)\n",
        "\n",
        "\n",
        "$\\newcommand{\\N}{\\mathbb{N}}\n",
        "\\newcommand{\\R}{\\mathbb{R}}\n",
        "\\newcommand{\\PP}{\\mathbb{P}}\n",
        "\\newcommand{\\fB}{\\mathfrak{B}}\n",
        "\\newcommand{\\fF}{\\mathfrak{F}}\n",
        "\\newcommand{\\cX}{\\mathcal{X}}\n",
        "$\n",
        "\n",
        "\n",
        "Ustalamy parametry startowe\n",
        "### Przykład"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "np.random.seed(42)  # for reproducibility\n",
        "N = 100             # more samples for the more complicated model\n",
        "mu_true, sigma_true = 1000, 15    # stochastic flux model\n",
        "\n",
        "F_true = stats.norm(mu_true, sigma_true).rvs(N)  # (unknown) true flux\n",
        "F = stats.poisson(F_true).rvs()   # observed flux: true flux plus Poisson errors.\n",
        "e = np.sqrt(F)  # root-N error, as above\n",
        "\n",
        "def log_prior0(theta):\n",
        "  # sigma needs to be positive. Czy wiemy coś jeszcze?\n",
        "  if theta[1] <= 0:\n",
        "    return -np.inf\n",
        "  else:\n",
        "    return 1/(1+theta[1])   # raczej 0 (rozkład jednostajny dla sigma>0), albo: np.log(theta[1]) - raczej NIE 0\n",
        "\n",
        "def log_likelihood(theta, F, e):\n",
        "  return -0.5 * np.sum(np.log(2 * np.pi * (theta[1] ** 2 + e ** 2))\n",
        "                         + (F - theta[0]) ** 2 / (theta[1] ** 2 + e ** 2))\n",
        "\n",
        "def log_posterior0(theta):\n",
        "  return log_prior0(theta) + log_likelihood(theta, F, e)\n",
        "\n",
        "ndim = 2        # number of parameters in the model\n",
        "nwalkers = 100   # number of MCMC walkers\n",
        "nsteps, nburn = 2000, 1000\n",
        "\n",
        "\n",
        "def compute_log_prob0(coords):\n",
        "  \"\"\"Calculate the vector of log-probability for the walkers\n",
        "  Args:\n",
        "      coords: (ndarray[..., ndim]) The position vector in parameter\n",
        "          space where the probability should be calculated.\n",
        "  \"\"\"\n",
        "  log_prob = np.array([log_posterior0(p, F, e) for p in coords])\n",
        "  return log_prob\n",
        "\n",
        "# we'll start at random locations\n",
        "starting_guesses = np.random.rand(nwalkers, ndim)\n",
        "starting_guesses[:, 0] *= 2000  # start mu between 0 and 2000\n",
        "starting_guesses[:, 1] *= 30    # start sigma between 0 and 20\n"
      ],
      "metadata": {
        "id": "-YfGDzT0T0tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rozkłady warunkowe i MC\n",
        "\n",
        "Przypominam (np. *Konstrukcje II:* *1.3.5, 2.1.4*), że dla dowolnych zmiennych losowych $X\\colon \\Omega\\to \\R^p,$ $Z\\colon\\Omega\\to\\R^m\\ $ **warunkowym rozkładem** zmiennej $X$ względem $Z$ nazywamy każdą (istnieją i są równe pw.) rodzinę borelowskich miar probabilistycznych\n",
        "$$\n",
        "\\PP_{X|Z} = \\left(\\PP_{X|Z=z}\\right)_{z\\in\\R^m}\\colon\\ \\R^m\\!\\times\\fB_{\\R^p}\\to[0,1]\n",
        "$$\n",
        "takich, że\n",
        "$$\n",
        "\\PP\\{X\\in A, Z\\in B\\}=\\int_B \\PP_{X|Z=z}(A)\\,\\PP_Z(dz)\\ \\text{ dla }\\ (A,B)\\in\\fB_{\\R^p}\\times\\fB_{\\R^m}.\n",
        "$$\n",
        "Wówczas także\n",
        "$$\n",
        "\\int_\\Omega h(X,Z)\\,d\\PP =\\int_{\\R^m}\\left(\\int_{\\R^p}h(x,z)\\PP_{X|Z=z}(dx) \\right)\\PP_Z(dz) \\quad\\text{ oraz} \\\\\n",
        "$$\n",
        "$$\n",
        "\\int_{X^{-1}A\\,\\cap\\, Z^{-1}B} h(X,Z)\\,d\\PP =\\int_{B}\\left(\\int_{A}h(x,z)\\PP_{X|Z=z}(dx) \\right)\\PP_Z(dz)\n",
        "$$\n",
        "dla dowolnej funkcji borelowskiej $h\\colon\\R^{m+p}\\to\\R$, dla której przynajmniej jedna ze stron ma skończony sens.\n",
        "\n",
        "Ogólna koncepcja **łańcuchów Markowa (MC)** zakłada, że ciąg wektorowych zmiennych losowych $\\ X_n\\colon \\cX\\to\\R^p,\\,n\\ge 0\\,,$   jest powiązany iteracyjną zależnością postaci\n",
        "$$\\begin{align}\n",
        "\\PP(X_{k+1}\\in C|X_0=x_0,\\ldots,X_k=x_k)&=\\PP(X_{k+1}\\in C|X_k=x_k) \\\\\n",
        "&=\\PP_{X_{k+1}|X_k=x_k}(C)\\\\\n",
        "&= K(x_k,C)\n",
        "\\end{align}$$\n",
        "dla $k\\ge 0$, $C\\in\\fB_{\\R^p}$ i dowolnych wartości $x_0,\\ldots,x_k\\in\\R^p,$ przy czym $$\\PP_{X_{k+1}|X_k}=K\\colon\\ \\R^p\\!\\times\\fB_{\\R^p}\\to[0,1]$$\n",
        "jest niezależnym od $k,$ ustalonym rozkładem warunkowym zwanym **jądrem przejścia** (ang. transition kernel).\n",
        "\n",
        ">Jeśli zmienne tworzące łańcuch są *dyskretne*, ich zbiór wartości jest co najwyżej przeliczalną *przestrzenią stanów*, a jądro przejścia opisuje macierz stochastyczna $[\\PP(X_{n+1}=j|X_n=i)]$ zawierająca prawdopodobieństwa przejścia $i\\leadsto j$  (od stanu $i$ do stanu $j$)."
      ],
      "metadata": {
        "id": "9jzDXE7JGoGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Oznaczmy $\\PP_{X_0}=\\mu.$ Ze względu na tożsamości\n",
        "$$\\begin{align}\n",
        "\\PP\\{(X_0,X_1)\\in A_0\\times A_1\\}&=\\int_{A_0}\\PP_{X_1|X_0=x_0}\\!(A_1)\\,\\PP_{X_0}(dx_0) \\\\\n",
        "&=\\int_{A_0}K(x_0,A_1)\\,\\mu(dx_0), \\\\\n",
        "\\PP\\{(X_0,X_1,X_2)\\in A_0\\times A_1\\times A_2\\}&=\\int_{A_0\\times A_1}\\PP_{X_2|(X_0,X_1)}\\!(A_2)\\,d\\PP_{(X_0,X_1)} \\\\\n",
        "&=\\int_{A_0\\times A_1}\\PP_{X_2|X_1=x_1}(A_2)\\,\\PP_{(X_0,X_1)}(dx_0,dx_1) \\\\\n",
        "&=\\int_{A_0}\\int_{A_1}K(x_1,A_2)K(x_0,dx_1\\!)\\,\\mu(dx_0) \\\\\n",
        "\\PP\\{(X_0,\\ldots,X_3)\\in A_0\\times \\cdots\\times A_3\\}&= \\int_{A_0}\\ldots\\int_{A_2}K(x_2,A_3)K(x_1,dx_2\\!)K(x_0,dx_1\\!)\\,\\mu(dx_0)\n",
        "\\end{align}$$\n",
        "(... itd.) rozkład *startowy* $\\mu$ wraz z jądrem przejścia $K$ wyznaczają jednoznacznie rozkład prawdopodobieństwa całego łańcucha Markowa -- w przestrzeni $(\\R^p)^\\infty$ -- oznaczany zazwyczaj jako $\\PP_\\mu.$\n",
        "\n",
        "> W szczególności, jeśli przyjąć $\\mu=\\delta_x$ (czyli $X_0\\equiv x\\in\\R^p$ jest stałe), rozważamy łańcuchy Markowa o zadanym *punkcie startowym* $x$ i rozkładach $\\PP_x$.  "
      ],
      "metadata": {
        "id": "7w3VCxpKoRHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Istnienie podanych wyżej całek, a więc istnienie i jednoznaczny opis rozkładów $\\PP_{(X_0,\\ldots,X_n)},$ $n\\in\\N,$ nie wymaga dodatkowych założeń - własności rozkładu $\\PP_\\mu$ wynikają z przyjętych jako punkt wyjścia własności rozkładów $\\mu$ i $K$.   \n",
        "Każdy z rozkładów $\\PP_{X_n}$ jest rozkładem brzegowym dla $\\PP_\\mu$ i wyraża się wzorem $\\PP\\{X_n\\in A\\} = \\int K^n(x,A)\\,\\mu(dx),$ gdzie $K^1\\equiv K$, a jądro *iterowane* $K^n$ jest splotem\n",
        "$$\n",
        "K^n(x_0,A) = \\int\\cdots\\int K(x_{n-1},A)K(x_{n-2},dx_{n-1})\\cdots K(x_0,dx_1)\n",
        "$$\n",
        "dla $n\\ge 2.$\n",
        "> Trywialny przykład jądra $\\ K(x,\\cdot)\\equiv\\kappa\\ $ - stałego, niezależnego od $x$, implikuje tożsamości  $\\ K^n=\\kappa=\\PP_{X_n}\\ $ dla $n\\ge 1,$ co podkreśla odmienny charakter rozkładu startowego $\\mu.$\n",
        "\n",
        "\n",
        "Zaawansowana teoria MC's dowodzi, że przy relatywnie niezbyt wymagających założeniach dotyczących jądra przejścia:\n",
        "* istnieje dokładnie jedna *stacjonarna* miara probabilistyczna $\\pi$ taka, że dla $\\mu\\equiv\\pi$ wszystkie kolejne zmienne łańcucha mają ten sam rozkład $\\PP_{X_n}\\equiv\\mu$\n",
        "* niezależnie od wyboru początkowego rozkładu $\\mu$, a wiec także - niezależnie od wyboru punktu startowego łańcucha, ciąg rozkładów $\\PP_{X_n}$ jest zbieżny (w sensie całkowitej wariancji) do rozkładu stacjonarnego $\\pi$.\n",
        "\n",
        "> Całkowitą wariację różnicy miar definiuje wzór\n",
        "$$\\|\\mu_1-\\mu_2\\|_{TV} = \\sup_A|\\mu_1(A)-\\mu_2(A)|\n",
        "$$\n",
        "\n",
        "**Stacjonarność rozkładu** $\\pi$ charakteryzuje pojedynczy warunek\n",
        "$$\n",
        "\\int K(x,A)\\,\\pi(dx) = \\pi(A)\\quad\\text{ dla } A\\in \\fB_{\\R^p}.\n",
        "$$\n"
      ],
      "metadata": {
        "id": "SPk-Qs3tFHIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Odwracanie kota ogonem\n",
        "Skoro skomplikowana i dość ogólna konstrukcja, jaką jest MC (łańcuch Markowa), generuje zbieżny ciąg rozkładów, a graniczna miara $\\pi$ jest jednoznacznie scharakteryzowana przez warunek stacjonarności, spróbujmy odwrócić kierunek rozumowania. Jeśli zatem *dana jest* miara probabilistyczna $\\pi$ na $\\cX\\subset\\R^p$, a przynajmniej jej gęstość $f$, to ewentualna konstrukcja *jądra przejścia* $K$ związanego z $f$ warunkiem stacjonarności\n",
        "$$ \\int K(x,A)f(x)\\,dx = \\int_A f(x)\\,dx\\quad\\text{ dla }A\\in\\fB_\\cX\n",
        "$$      \n",
        "pozwala traktować $\\pi$ jako granicę ciągu rozkładów $\\PP_{X_n}$ pewnego łańcucha Markowa.   \n",
        "Warunek stacjonarności może być *łatwy do sprawdzenia*, jeśli $K$ w jawny sposób zależy od  funkcji gęstości $f$ - w takim przypadku iteracyjnie tworzone próbki rozkładów $\\PP_{X_n}$ powinny być(?) zbieżne(?) do próbki rozkładu $\\pi$.  \n",
        "\n",
        "Jest to wprawdzie pewna komplikacja, ale także szansa na uzyskanie przybliżonego rozkładu i - w szczególności - możliwość przybliżonego, numerycznego wyznaczania związanych z $\\pi$ wartości oczekiwanych (całek względem miary).\n",
        "\n",
        "\n",
        "\n",
        "####  Algorytm Nicolasa Metropolis (1953) ... i Wilfreda K. Hastingsa (1970) jako **przykład**\n",
        "Podstawowa koncepcja generowania próby\n"
      ],
      "metadata": {
        "id": "CdPwL9wvdkyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mh_sampler(x0, lnprob_fn, prop_fn, prop_fn_kwargs={}, iterations=100000):\n",
        "    \"\"\"Simple metropolis hastings sampler.\n",
        "\n",
        "    :param x0: Initial array of parameters.\n",
        "    :param lnprob_fn: Function to compute log-posterior.\n",
        "    :param prop_fn: Function to perform jumps.\n",
        "    :param prop_fn_kwargs: Keyword arguments for proposal function\n",
        "    :param iterations: Number of iterations to run sampler. Default=100000\n",
        "\n",
        "    :returns:\n",
        "        (chain, acceptance, lnprob) tuple of parameter chain , acceptance rate\n",
        "        and log-posterior chain.\n",
        "    \"\"\"\n",
        "\n",
        "    # number of dimensions\n",
        "    ndim = len(x0)\n",
        "\n",
        "    # initialize chain, acceptance rate and lnprob\n",
        "    chain = np.zeros((iterations, ndim))\n",
        "    lnprob = np.zeros(iterations)\n",
        "    accept_rate = np.zeros(iterations)\n",
        "\n",
        "    # first samples\n",
        "    chain[0] = x0\n",
        "    lnprob0 = lnprob_fn(x0)\n",
        "    lnprob[0] = lnprob0\n",
        "\n",
        "    # start loop\n",
        "    naccept = 0\n",
        "    for ii in range(1, iterations):\n",
        "\n",
        "        # propose\n",
        "        x_star, factor = prop_fn(x0, **prop_fn_kwargs)\n",
        "\n",
        "        # draw random uniform number\n",
        "        u = np.random.uniform(0, 1)\n",
        "\n",
        "        # compute hastings ratio\n",
        "        lnprob_star = lnprob_fn(x_star)\n",
        "        H = np.exp(lnprob_star - lnprob0) * factor\n",
        "\n",
        "        # accept/reject step (update acceptance counter)\n",
        "        if u < H:\n",
        "            x0 = x_star\n",
        "            lnprob0 = lnprob_star\n",
        "            naccept += 1\n",
        "\n",
        "        # update chain\n",
        "        chain[ii] = x0\n",
        "        lnprob[ii] = lnprob0\n",
        "        accept_rate[ii] = naccept / ii\n",
        "\n",
        "    return chain, accept_rate, lnprob"
      ],
      "metadata": {
        "id": "xp8BhkXQnH6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_proposal(x, sigma=0.1):\n",
        "    \"\"\"\n",
        "    Gaussian proposal distribution.\n",
        "\n",
        "    Draw new parameters from Gaussian distribution with\n",
        "    mean at current position and standard deviation sigma.\n",
        "\n",
        "    Since the mean is the current position and the standard\n",
        "    deviation is fixed. This proposal is symmetric so the ratio\n",
        "    of proposal densities is 1.\n",
        "\n",
        "    :param x: Parameter array\n",
        "    :param sigma:\n",
        "        Standard deviation of Gaussian distribution. Can be scalar\n",
        "        or vector of length(x)\n",
        "\n",
        "    :returns: (new parameters, ratio of proposal densities)\n",
        "    \"\"\"\n",
        "\n",
        "    # Draw x_star\n",
        "    x_star = x + np.random.randn(len(x)) * sigma\n",
        "\n",
        "    # proposal ratio factor is 1 since jump is symmetric\n",
        "    qxx = 1\n",
        "\n",
        "    return (x_star, qxx)\n",
        "\n",
        "# x0 = np.random.randn(1)\n",
        "chain, ar, lnprob = mh_sampler(starting_guesses, log_posterior0, gaussian_proposal,\n",
        "                                prop_fn_kwargs={'sigma':sigma})\n"
      ],
      "metadata": {
        "id": "6912WN8un7O1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}